{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45859,
     "status": "ok",
     "timestamp": 1748308328574,
     "user": {
      "displayName": "YONGHAO XU",
      "userId": "05923948742615568131"
     },
     "user_tz": -600
    },
    "id": "wfUGh8BvNByG",
    "outputId": "56425d09-6ea7-4872-f2fe-1271fe580a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "\n",
      "Searching best ARIMA(p,d,q) order...\n",
      "Failed ARIMA(0, 0, 0): A constant trend was included in the model specification, but the `exog` data already contains a column of constants.\n",
      "Failed ARIMA(0, 0, 1): A constant trend was included in the model specification, but the `exog` data already contains a column of constants.\n",
      "Failed ARIMA(0, 0, 2): A constant trend was included in the model specification, but the `exog` data already contains a column of constants.\n",
      "ARIMA(0, 1, 0) AIC: 3140.83\n",
      "ARIMA(0, 1, 1) AIC: 3119.43\n",
      "ARIMA(0, 1, 2) AIC: 3117.99\n",
      "ARIMA(0, 2, 0) AIC: 3481.03\n",
      "ARIMA(0, 2, 1) AIC: 3141.84\n",
      "ARIMA(0, 2, 2) AIC: 3121.13\n",
      "Failed ARIMA(1, 0, 0): A constant trend was included in the model specification, but the `exog` data already contains a column of constants.\n",
      "Failed ARIMA(1, 0, 1): A constant trend was included in the model specification, but the `exog` data already contains a column of constants.\n",
      "Failed ARIMA(1, 0, 2): A constant trend was included in the model specification, but the `exog` data already contains a column of constants.\n",
      "ARIMA(1, 1, 0) AIC: 3123.78\n",
      "ARIMA(1, 1, 1) AIC: 3105.81\n",
      "ARIMA(1, 1, 2) AIC: 3101.65\n",
      "ARIMA(1, 2, 0) AIC: 3330.63\n",
      "ARIMA(1, 2, 1) AIC: 3125.23\n",
      "ARIMA(1, 2, 2) AIC: 3111.27\n",
      "Failed ARIMA(2, 0, 0): A constant trend was included in the model specification, but the `exog` data already contains a column of constants.\n",
      "Failed ARIMA(2, 0, 1): A constant trend was included in the model specification, but the `exog` data already contains a column of constants.\n",
      "Failed ARIMA(2, 0, 2): A constant trend was included in the model specification, but the `exog` data already contains a column of constants.\n",
      "ARIMA(2, 1, 0) AIC: 3121.58\n",
      "ARIMA(2, 1, 1) AIC: 3101.98\n",
      "ARIMA(2, 1, 2) AIC: 3103.71\n",
      "ARIMA(2, 2, 0) AIC: 3265.89\n",
      "ARIMA(2, 2, 1) AIC: 3123.24\n",
      "ARIMA(2, 2, 2) AIC: 3125.90\n",
      "\n",
      "ARIMA(1, 1, 2) model saved to: /content/drive/MyDrive/Colab Notebooks/Group Assignment/Version 4/TrainedModel/TimeSeries/arima_model.pkl\n",
      "Model trained up to: 2022-07-20 13:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from itertools import product\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from google.colab import drive\n",
    "\n",
    "\n",
    "# === Constants ===\n",
    "DATA_PATH = 'C:/Swinburne/2025Sem1/COS40007-Artificial Intelligence for Engineering/Group Assignment/5G Zone Prediction System/ProcessedData/clean_data_clst.csv'\n",
    "MODEL_SAVE_PATH = 'C:/Swinburne/2025Sem1/COS40007-Artificial Intelligence for Engineering/Group Assignment/5G Zone Prediction System/TrainedModel/TimeSeries/arima_model.pkl'\n",
    "TEST_SIZE = 24\n",
    "VAL_SIZE = 24\n",
    "ARIMA_PARAM_GRID = list(product(range(3), repeat=3))  # Try (0â€“2) for p, d, q\n",
    "\n",
    "# === Feature Engineering Function ===\n",
    "def create_features(df, target_col='total_throughput'):\n",
    "    df = df.copy()\n",
    "    df['hour'] = df.index.hour\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['minute'] = df.index.minute\n",
    "\n",
    "    # Cyclical encodings\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['minute_sin'] = np.sin(2 * np.pi * df['minute'] / 60)\n",
    "    df['minute_cos'] = np.cos(2 * np.pi * df['minute'] / 60)\n",
    "\n",
    "    # Rolling stats\n",
    "    for w in [3, 6, 12, 24]:\n",
    "        df[f'{target_col}_mean_{w}'] = df[target_col].rolling(window=w, min_periods=1).mean()\n",
    "        df[f'{target_col}_std_{w}'] = df[target_col].rolling(window=w, min_periods=1).std()\n",
    "        df[f'{target_col}_min_{w}'] = df[target_col].rolling(window=w, min_periods=1).min()\n",
    "        df[f'{target_col}_max_{w}'] = df[target_col].rolling(window=w, min_periods=1).max()\n",
    "        df[f'{target_col}_skew_{w}'] = df[target_col].rolling(window=w, min_periods=1).skew()\n",
    "        df[f'{target_col}_roc_{w}'] = df[target_col].pct_change(periods=w)\n",
    "\n",
    "    # Interaction\n",
    "    df['hour_interaction'] = df['hour'] * df[target_col]\n",
    "\n",
    "    # Cleanup\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).ffill().bfill()\n",
    "\n",
    "    return df\n",
    "\n",
    "# === Load and preprocess raw data ===\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df['Convert_time'] = pd.to_datetime(df['DATES'] + ' ' + df['TIME'])\n",
    "df.set_index('Convert_time', inplace=True)\n",
    "\n",
    "# === Resample and feature engineering ===\n",
    "hourly_data = df.resample('h').agg({'total_throughput': 'mean'}).bfill().ffill()\n",
    "data = create_features(hourly_data)\n",
    "\n",
    "# === Train/Val/Test split ===\n",
    "if len(data) < TEST_SIZE + VAL_SIZE + 1:\n",
    "    raise ValueError(\"Not enough data for ARIMA training\")\n",
    "\n",
    "train_data = data[:-TEST_SIZE - VAL_SIZE]\n",
    "val_data = data[-TEST_SIZE - VAL_SIZE:-TEST_SIZE]\n",
    "test_data = data[-TEST_SIZE:]\n",
    "\n",
    "# === Select exogenous features ===\n",
    "# Only include time-based features that can be recreated during future forecasting\n",
    "time_exog_cols = ['hour', 'day_of_week', 'minute',\n",
    "                  'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'minute_sin', 'minute_cos']\n",
    "\n",
    "# Filter to what's available in data (safe subset)\n",
    "exog_cols = [col for col in time_exog_cols if col in data.columns]\n",
    "\n",
    "# === Grid Search for ARIMA(p,d,q) ===\n",
    "print(\"\\nSearching best ARIMA(p,d,q) order...\")\n",
    "best_aic = float('inf')\n",
    "best_order = None\n",
    "fitted_model = None\n",
    "\n",
    "for order in ARIMA_PARAM_GRID:\n",
    "    try:\n",
    "        model = ARIMA(train_data['total_throughput'], order=order, exog=train_data[exog_cols])\n",
    "        fitted = model.fit()\n",
    "        aic = fitted.aic\n",
    "        print(f\"ARIMA{order} AIC: {aic:.2f}\")\n",
    "        if aic < best_aic:\n",
    "            best_aic = aic\n",
    "            best_order = order\n",
    "            fitted_model = fitted\n",
    "    except Exception as e:\n",
    "        print(f\"Failed ARIMA{order}: {e}\")\n",
    "        continue\n",
    "\n",
    "if fitted_model is None:\n",
    "    raise RuntimeError(\"All ARIMA configurations failed.\")\n",
    "\n",
    "# === Save model ===\n",
    "last_train_timestamp = train_data.index.max()\n",
    "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "with open(MODEL_SAVE_PATH, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'fitted_model': fitted_model,\n",
    "        'target_column': 'total_throughput',\n",
    "        'last_train_timestamp': last_train_timestamp,\n",
    "        'best_order': best_order,\n",
    "        'features': exog_cols\n",
    "    }, f)\n",
    "\n",
    "print(f\"\\nARIMA{best_order} model saved to: {MODEL_SAVE_PATH}\")\n",
    "print(f\"Model trained up to: {last_train_timestamp}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNtpwkvj+7TNFRfLtlDzahl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
